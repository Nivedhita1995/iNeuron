{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fe3ac3f4",
   "metadata": {},
   "source": [
    "1. What are the key tasks that machine learning entails? What does data pre-processing imply?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ec0d88f",
   "metadata": {},
   "source": [
    "Key tasks in machine learning are:\n",
    "    Data collection\n",
    "    Data preprocessing\n",
    "    Feature engineering\n",
    "    Model selection\n",
    "    Model training\n",
    "    Model evaluation\n",
    "    Model tuning and optimization\n",
    "    Model deployment and inference\n",
    "    \n",
    "Data preprocessing refers to the steps taken to clean, transform, and prepare the raw data before it can be used for training machine learning models.\n",
    "Data preprocessing aims to ensure that the data is in a suitable format, free from errors, and optimized for the chosen machine learning algorithm. It helps to improve model accuracy, robust\n",
    "\n",
    "Data pre-processing involves:\n",
    "   Data cleaning\n",
    "   Data transformation\n",
    "   Feature encoding\n",
    "   Feature selection\n",
    "   Handling imbalanced data\n",
    "   Splitting data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04bc972e",
   "metadata": {},
   "source": [
    "2. Describe quantitative and qualitative data in depth. Make a distinction between the two."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e82e3d9d",
   "metadata": {},
   "source": [
    "Quantitative Data:\n",
    "Quantitative data refers to information that is expressed in numerical form and can be quantified or measured.\n",
    "Key characteristics of quantitative data:\n",
    "    Measurement\n",
    "    Numerical representation\n",
    "    Statistical analysis\n",
    "    Objective and generalizable\n",
    "    Large sample sizes\n",
    "    \n",
    "Qualitative Data:\n",
    "Qualitative data refers to non-numerical information that is descriptive and subjective in nature.\n",
    "Key characteristics of qualitative data:\n",
    "    Description and interpretation\n",
    "    Coding and thematic analysis\n",
    "    Narrative or textual form\n",
    "    Smaller sample sizes\n",
    "    \n",
    "Quantitative data involves numerical measurements and statistical analysis, aiming for objectivity and generalizability. It is suitable for analyzing patterns and relationships on a larger scale. Qualitative data, on the other hand, is descriptive and interpretive, focusing on capturing subjective experiences, meanings, and contextual details."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff60df20",
   "metadata": {},
   "source": [
    "3. Create a basic data collection that includes some sample records. Have at least one attribute from\n",
    "each of the machine learning data types."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bfc945f",
   "metadata": {},
   "source": [
    "Data collection related to student performance:\n",
    "\n",
    "Data 1:\n",
    "\n",
    "ID: 1001\n",
    "Age: 18 (Quantitative - Numerical)\n",
    "Gender: Female (Qualitative - Categorical)\n",
    "Grade Level: 12 (Quantitative - Ordinal)\n",
    "Math Score: 85 (Quantitative - Numerical)\n",
    "\n",
    "Data 2:\n",
    "\n",
    "ID: 1002\n",
    "Age: 17 (Quantitative - Numerical)\n",
    "Gender: Male (Qualitative - Categorical)\n",
    "Grade Level: 11 (Quantitative - Ordinal)\n",
    "Math Score: 72 (Quantitative - Numerical)\n",
    "\n",
    "Data 3:\n",
    "\n",
    "ID: 1003\n",
    "Age: 16 (Quantitative - Numerical)\n",
    "Gender: Female (Qualitative - Categorical)\n",
    "Grade Level: 10 (Quantitative - Ordinal)\n",
    "Math Score: 90 (Quantitative - Numerical)\n",
    "\n",
    "Each record represents a student and includes attributes such as ID, Age and Math Score (quantitative - numerical), Gender (qualitative - categorical) and Grade Level (quantitative - ordinal)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "093fb0bb",
   "metadata": {},
   "source": [
    "4. What are the various causes of machine learning data issues? What are the ramifications?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67080d98",
   "metadata": {},
   "source": [
    "The common causes of machine learning data issues and their potential ramifications:\n",
    "    \n",
    "Insufficient or biased data:\n",
    "    Models trained on insufficient or biased data may produce inaccurate or biased predictions, leading to poor generalization and unfair outcomes.\n",
    "    \n",
    "Noisy or inconsistent data:\n",
    "    Noisy data can impact model performance, leading to unreliable predictions and reduced accuracy. \n",
    "    \n",
    "Missing data:\n",
    "    Missing data can result in biased or incomplete models as the missing values may contain valuable information.\n",
    "    \n",
    "Imbalanced data:\n",
    "    Imbalanced data can lead to biased models that favor majority classes. \n",
    "    \n",
    "Data leakage:\n",
    "    Data leakage can create overly optimistic performance metrics during model development, leading to models that fail to generalize well to new, unseen data.\n",
    "    \n",
    "Data inconsistency and mismatch:\n",
    "    Inconsistent or mismatched data can introduce biases or confounding factors, making it difficult to identify meaningful patterns or relationships accurately.\n",
    "    \n",
    "Feature selection and engineering issues:\n",
    "    Poor feature selection or engineering can lead to suboptimal models, reducing predictive power and limiting the ability to capture essential patterns or relationships in the data.\n",
    "    \n",
    "Overfitting or underfitting:\n",
    "    Underfitting results in models that are too simplistic and fail to capture the underlying patterns, while overfitting leads to models that memorize the training data but fail to generalize to new data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e752586a",
   "metadata": {},
   "source": [
    "5. Demonstrate various approaches to categorical data exploration with appropriate examples."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c3a83e4",
   "metadata": {},
   "source": [
    "The three common approaches to categorical data exploration with examples:\n",
    "    \n",
    "Frequency Distribution:\n",
    "    \n",
    "This approach involves calculating the frequency or count of each category in the dataset. It provides an overview of the distribution and relative occurrence of each category.\n",
    "    Example:Customer feedback on a product, with categorical variables as ratings.\n",
    "    \t\n",
    "      Ratings      Frequency\n",
    "        5             25  \n",
    "        4             18\n",
    "        3             30\n",
    "        2             10\n",
    "        1             20\n",
    "        \n",
    "   From this frequency distribution, we can observe the distribution of ratings levels and identify which category has the highest or lowest occurrence. \n",
    "   \n",
    "Bar Plot/Bar Chart:\n",
    "\n",
    "This approach involves visualizing the categorical data using bar plots or bar charts, where the height or length of each bar represents the frequency or count of each category.\n",
    "    Example:Customer feedback on a product, with categorical variables as ratings.\n",
    "    \n",
    "    Ratings      Frequency\n",
    "        5             25  \n",
    "        4             18\n",
    "        3             30\n",
    "        2             10\n",
    "        1             20\n",
    "        \n",
    "    The bar plot clearly shows the distribution of satisfaction levels and allows for easy comparison of the frequencies across categories.\n",
    "    \n",
    "Cross-tabulation/Contingency Table:\n",
    "\n",
    "This approach involves creating a cross-tabulation or contingency table, which displays the relationship between two categorical variables by counting the occurrences in each combination of categories.\n",
    "    Example:Consider a dataset of students' academic performance, with two categorical variables: \"Grade Level\" (categories: 10th,12th) and \"Subject\" (categories: Math, Science, English). \n",
    "     \n",
    "     \t Grade      Math\t  Science\t   English\n",
    "         10th \t     60         89           78\n",
    "         12th        75         93           80\n",
    "       This cross-tabulation provides insights into the distribution of subjects across different grade levels, allowing for comparisons and identifying any patterns or trends.    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96334fc7",
   "metadata": {},
   "source": [
    "6. How would the learning activity be affected if certain variables have missing values? Having said\n",
    "that, what can be done about it?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6686ab44",
   "metadata": {},
   "source": [
    "Here's how missing values can affect the learning activity and some common techniques to handle them:\n",
    "\n",
    "Reduced Sample Size:The sample size decreases, which can lead to a loss of valuable information and potentially reduce the representativeness of the data.\n",
    "Biased Results: If the missing values are not handled appropriately, it can introduce bias into the analysis. \n",
    "Incomplete Patterns: Missing values can disrupt the patterns and relationships in the data, making it difficult for the learning algorithm to capture the underlying structure accurately.\n",
    "\n",
    "To address the issue of missing values, several techniques can be applied:\n",
    "Deletion: The simplest approach is to delete the observations or variables with missing values.\n",
    "Imputation: Imputation involves estimating or filling in the missing values with substitute values. Common imputation techniques include mean imputation (replacing missing values with the mean of the variable), median imputation, mode imputation, or regression imputation (predicting missing values based on other variables).\n",
    "Indicator Variables: Another approach is to create an indicator variable that indicates the presence or absence of missing values for each variable.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93e6f1e5",
   "metadata": {},
   "source": [
    "7. Describe the various methods for dealing with missing data values in depth."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33694920",
   "metadata": {},
   "source": [
    "Methods for handling missing data in depth:\n",
    "    Deletion Methods\n",
    "    Imputation Methods\n",
    "    Advanced Methods\n",
    "    \n",
    "Deletion Methods:\n",
    "\n",
    "Listwise Deletion: In this method, also known as complete-case analysis, any observation with missing values is entirely removed from the dataset. It is a straightforward approach but can lead to a loss of valuable information if the missingness is not completely random.\n",
    "Pairwise Deletion: In this method, only the specific variables involved in an analysis are considered, and observations with missing values for those variables are excluded. This method retains more data compared to listwise deletion but may introduce bias if the missingness is related to the excluded variables.\n",
    "\n",
    "Imputation Methods:\n",
    "\n",
    "Mean/Median/Mode Imputation: In this method, missing values in a variable are replaced with the mean, median, or mode of the non-missing values of that variable.\n",
    "Regression Imputation: Missing values can be predicted using regression models. A regression model is built using other variables as predictors, and missing values are imputed based on the predicted values.\n",
    "Advanced Methods:K-Nearest Neighbors (KNN) Imputation: KNN imputation imputes missing values by finding the K-nearest neighbors based on other variables and using their values to impute the missing values. It considers the local relationships between observations.\n",
    "Data-Driven Imputation: Machine learning algorithms, such as decision trees or random forests, can be used to impute missing values. These algorithms learn patterns from the observed data and use them to predict the missing values."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5c5f345",
   "metadata": {},
   "source": [
    "8. What are the various data pre-processing techniques? Explain dimensionality reduction and\n",
    "function selection in a few words."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ad4e5dc",
   "metadata": {},
   "source": [
    "The common data pre-processing techniques include:\n",
    "Data Cleaning: This involves handling missing values, dealing with duplicates, and correcting inconsistent or erroneous data.\n",
    "\n",
    "Data Integration: Combining data from multiple sources into a single dataset to facilitate analysis.\n",
    "\n",
    "Data Transformation: Applying mathematical or statistical transformations to normalize or scale data, such as logarithmic or z-score transformations.\n",
    "\n",
    "Feature Selection: Identifying the most relevant features or variables that contribute significantly to the target variable, while discarding irrelevant or redundant ones.\n",
    "\n",
    "Dimensionality Reduction: Reducing the number of variables or features in a dataset while retaining important information. This helps in simplifying models, improving computational efficiency, and addressing the curse of dimensionality.\n",
    "\n",
    "Dimensionality reduction aims to overcome the challenges posed by high-dimensional data by reducing the number of input variables. It involves techniques like Principal Component Analysis (PCA) and t-distributed Stochastic Neighbor Embedding (t-SNE). These techniques find new, lower-dimensional representations of the data that preserve important patterns and relationships.\n",
    "\n",
    "Function selection, refers to the process of choosing an appropriate mathematical or statistical function that best represents the relationship between input variables and the target variable. This is particularly relevant in machine learning, where different algorithms require different types of functions (e.g., linear, polynomial, exponential) to model the data accurately."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85988880",
   "metadata": {},
   "source": [
    "9.\n",
    "i. What is the IQR? What criteria are used to assess it?\n",
    "\n",
    "ii. Describe the various components of a box plot in detail? When will the lower whisker\n",
    "surpass the upper whisker in length? How can box plots be used to identify outliers?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "628a586b",
   "metadata": {},
   "source": [
    "i. What is the IQR? What criteria are used to assess it?\n",
    "\n",
    "IQR stands for Interquartile Range. \n",
    "It is a statistical measure used to assess the spread or dispersion of a dataset. \n",
    "The IQR represents the range between the first quartile (Q1) and the third quartile (Q3) of a dataset when the data is sorted in ascending order.\n",
    "Q1 is the first quartile of the data => 25% of the data lies between minimum and Q1.\n",
    "Q3 is the third quartile of the data => 75% of the data lies between minimum and Q3.\n",
    "The difference between Q3 and Q1 is called the Inter-Quartile Range or IQR.\n",
    "\n",
    "The IQR is often used in conjunction with a criterion known as the \"1.5 IQR rule\" to identify potential outliers in a dataset. According to this rule, any value that falls below Q1 - 1.5 * IQR or above Q3 + 1.5 * IQR is considered a potential outlier. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34204274",
   "metadata": {},
   "source": [
    "ii. Describe the various components of a box plot in detail? When will the lower whisker\n",
    "surpass the upper whisker in length? How can box plots be used to identify outliers?\n",
    "\n",
    "A box plot, also known as a box-and-whisker plot, is a graphical representation of the distribution of a dataset. \n",
    "The various components of a box plot include:\n",
    "Whiskers: The whiskers extend from the box and indicate the range of the data outside the IQR. There are typically two types of whiskers:\n",
    "\n",
    "a. Lower Whisker: It extends from the box to the lowest value within Q1 - 1.5 * IQR or the minimum value in the dataset, whichever is lower.\n",
    "\n",
    "b. Upper Whisker: It extends from the box to the highest value within Q3 + 1.5 * IQR or the maximum value in the dataset, whichever is higher.\n",
    "\n",
    "Outliers: Outliers are individual data points that fall beyond the whiskers. They are often represented as individual points on the plot. Outliers can be potential anomalies or extreme values that are significantly different from the rest of the dataset. \n",
    "\n",
    "=> The lower whisker will surpass the upper whisker in length when the data is skewed to the left (negatively skewed). \n",
    "\n",
    "=> Box plots can be used to identify outliers in a dataset by visually inspecting the plot. Any data points that fall beyond the whiskers are potential outliers."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b527195",
   "metadata": {},
   "source": [
    "10. Make brief notes on any two of the following:\n",
    "\n",
    "1. Data collected at regular intervals\n",
    "\n",
    "2. The gap between the quartiles\n",
    "\n",
    "3. Use a cross-tab"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07178c96",
   "metadata": {},
   "source": [
    "It provides information about the variability of the dataset within the central portion of the distribution.It provides information about the variability of the dataset within the central portion of the distribution.1. Data collected at regular intervals:\n",
    "\n",
    "Data collected at regular intervals (Interval data), refers to a specific sampling or measurement scheme where observations are recorded at consistent and predetermined time points or intervals. \n",
    "\n",
    "Data collected at regular intervals provides valuable insights into the dynamics and patterns over time.\n",
    "\n",
    "Interval data is one of the two types of discrete data.\n",
    "\n",
    "This regularity in data collection can have several implications and considerations:\n",
    "Time Series Analysis\n",
    "Temporal Relationships\n",
    "Seasonality and Trends\n",
    "Data Aggregation\n",
    "Missing or Irregular Intervals\n",
    "\n",
    "2. The gap between the quartiles\n",
    "\n",
    "The gap between the quartiles, also known as the interquartile range (IQR), is a measure of the spread or dispersion of a dataset. \n",
    "\n",
    "It provides information about the variability of the dataset within the central portion of the distribution.\n",
    "\n",
    "Mathematically, IQR = Q3 - Q1.\n",
    "The difference between Q3 and Q1 is called the Inter-Quartile Range or IQR.\n",
    "\n",
    "It is a robust measure of spread that is not influenced by extreme values or outliers. It focuses on the middle portion of the data, making it useful for summarizing the variability of a dataset without being heavily influenced by extreme observations.\n",
    "\n",
    "A larger IQR indicates a greater spread or dispersion of the data, suggesting a wider range of values within the central portion of the distribution. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbc47ede",
   "metadata": {},
   "source": [
    "11. Make a comparison between:\n",
    "\n",
    "1. Data with nominal and ordinal values\n",
    "\n",
    "2. Histogram and box plot\n",
    "\n",
    "3. The average and median"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4155b45",
   "metadata": {},
   "source": [
    "1. Data with nominal and ordinal values\n",
    "\n",
    "Data with nominal and ordinal values represent different types of categorical variables. \n",
    "\n",
    "Nature of Categories:\n",
    "Nominal Data: Nominal data represents categories or labels that do not have any inherent order or hierarchy. The categories are distinct and mutually exclusive. Examples include colors, genders, or categories like \"dog,\" \"cat,\" and \"bird.\"\n",
    "Ordinal Data: Ordinal data also represents categories, but they have a natural order or ranking associated with them. The categories have a relative position or hierarchy. Examples include ratings, levels of satisfaction (e.g., \"poor,\" \"average,\" \"good\")\n",
    "\n",
    "Data Analysis:\n",
    "Nominal Data: Nominal data is typically analyzed using frequency distributions, cross-tabulations, or measures like mode. It is suitable for counting and identifying the most common or prevalent categories within a dataset.\n",
    "Ordinal Data: Ordinal data allows for a broader range of analysis. In addition to frequency distributions, it enables the use of measures like median, percentiles, or rank correlations. \n",
    "\n",
    "Data Representation:\n",
    "Nominal Data: Nominal data is often represented using labels or codes, such as assigning numbers to different categories. The numerical values assigned are arbitrary and carry no quantitative meaning.\n",
    "Ordinal Data: Ordinal data is also represented using labels or codes, but these codes have a logical ordering. The numerical representation reflects the relative positions or levels of the categories.\n",
    "\n",
    "\n",
    "2. Histogram and box plot\n",
    "\n",
    "Histogram and box plot are both graphical representations used to summarize and visualize the distribution of a dataset.\n",
    "\n",
    "Histograms provide a detailed visualization of the distribution shape and frequency, while box plots offer a compact summary of key statistics, including central tendency, spread, and outlier detection. The choice between histogram and box plot depends on the specific data characteristics, the level of detail required, and the focus on summary statistics versus visual distribution."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3db0a240",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
